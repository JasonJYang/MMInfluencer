{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = 'xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data/kg_dr/processed')\n",
    "save_dir = Path('saved/kuzu_rag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df = pd.read_csv(data_dir.joinpath('kg_processed-suitable_category.csv'))\n",
    "print('The shape of the KG dataframe:', kg_df.shape)\n",
    "kg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = pd.read_csv(data_dir.joinpath('nodes.csv'))\n",
    "print('The shape of the node dataframe:', node_df.shape)\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(data_dir.joinpath('labels-suitable_category.csv'))\n",
    "print('The shape of the label dataframe:', label_df.shape)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(use_multimodal=False):\n",
    "    data_dir = Path('data/kg_dr/processed')\n",
    "    if use_multimodal:\n",
    "        kg_df = pd.read_csv(data_dir.joinpath('kg_processed-suitable_category.csv'))\n",
    "        label_df = pd.read_csv(data_dir.joinpath('labels-suitable_category.csv'))\n",
    "    else:\n",
    "        kg_df = pd.read_csv(data_dir.joinpath('kg_processed_no_multimodal-suitable_category.csv'))\n",
    "        label_df = pd.read_csv(data_dir.joinpath('labels_no_multimodal-suitable_category.csv'))\n",
    "\n",
    "    node_kg_list = list(set(kg_df['source']) | set(kg_df['target']))\n",
    "    print('The shape of the KG dataframe:', kg_df.shape)\n",
    "    print('The shape of the label dataframe:', label_df.shape)\n",
    "\n",
    "    node_df = pd.read_csv(data_dir.joinpath('nodes.csv'))\n",
    "    print('The shape of the node dataframe:', node_df.shape)\n",
    "    node_df = node_df[node_df['name'].isin(node_kg_list)]\n",
    "    print('The shape of the node dataframe after filtering:', node_df.shape)\n",
    "    # for nodes whose attribute is username, change the attribute to influencer\n",
    "    node_df.loc[node_df['attribute'] == 'username', 'attribute'] = 'influencer'\n",
    "    \n",
    "    return kg_df, node_df, label_df\n",
    "\n",
    "def create_node_table(nodes_df):\n",
    "    node_df_dict = {}\n",
    "    attribute_list = list(set(nodes_df['attribute'].unique()))\n",
    "    for attribute in attribute_list:\n",
    "        attribute_df = nodes_df[nodes_df['attribute'] == attribute]\n",
    "        attribute_df = attribute_df[['name', 'attribute']]\n",
    "        attribute_df = attribute_df.drop_duplicates(subset=['name'])\n",
    "        attribute_df = attribute_df.dropna(subset=['name'])\n",
    "        # first letter uppercase\n",
    "        attribute = attribute.capitalize()\n",
    "        print('The shape of the', attribute, 'dataframe is:', attribute_df.shape)\n",
    "        node_df_dict[attribute] = attribute_df\n",
    "    return node_df_dict\n",
    "\n",
    "def explore_edge_table(edges_df, nodes_df):\n",
    "    nodes_filder_df = nodes_df.dropna(subset=['name'])\n",
    "    edges_df = edges_df[(edges_df['source'].isin(nodes_filder_df['name'])) & (edges_df['target'].isin(nodes_filder_df['name']))]\n",
    "    node2attribute_dict = dict(zip(nodes_filder_df['name'], nodes_filder_df['attribute']))\n",
    "\n",
    "    relationship_list = list(set(edges_df['relationship'].unique()))\n",
    "    for relationship in relationship_list:\n",
    "        relationship_df = edges_df[edges_df['relationship'] == relationship]\n",
    "        relationship_df = relationship_df[['source', 'target', 'relationship']]\n",
    "        relationship_df = relationship_df.drop_duplicates()\n",
    "        relationship_df = relationship_df.dropna(subset=['source', 'target', 'relationship'])\n",
    "        relationship_df['source_attribute'] = relationship_df['source'].map(node2attribute_dict)\n",
    "        relationship_df['target_attribute'] = relationship_df['target'].map(node2attribute_dict)\n",
    "        print('The shape of the', relationship, 'dataframe is:', relationship_df.shape)\n",
    "        print('The combination of source attribute and target attribute:')\n",
    "        print(relationship_df[['source_attribute', 'target_attribute']].value_counts())\n",
    "        print('\\n')\n",
    "\n",
    "def create_edge_table(edges_df, nodes_df, node_df_dict):\n",
    "    node_list = []\n",
    "    for df in node_df_dict.values():\n",
    "        node_list.extend(df['name'].tolist())\n",
    "    node_list = list(set(node_list))\n",
    "    edges_df = edges_df[(edges_df['source'].isin(node_list)) & (edges_df['target'].isin(node_list))]\n",
    "    \n",
    "    nodes_filder_df = nodes_df.dropna(subset=['name'])\n",
    "    node2attribute_dict = dict(zip(nodes_filder_df['name'], nodes_filder_df['attribute']))\n",
    "    \n",
    "    edge_df_dict = {}\n",
    "    relationship_list = list(set(edges_df['relationship'].unique()))\n",
    "    for relationship in relationship_list:\n",
    "        relationship_df = edges_df[edges_df['relationship'] == relationship]\n",
    "        relationship_df = relationship_df[['source', 'target', 'relationship']]\n",
    "        relationship_df = relationship_df.drop_duplicates()\n",
    "        relationship_df = relationship_df.dropna(subset=['source', 'target', 'relationship'])\n",
    "        relationship_df['source_attribute'] = relationship_df['source'].map(node2attribute_dict)\n",
    "        relationship_df['target_attribute'] = relationship_df['target'].map(node2attribute_dict)\n",
    "        relationship = relationship.capitalize()\n",
    "\n",
    "        if relationship == 'Recommend_product':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "            relationship = 'Recommend'\n",
    "        \n",
    "        if relationship == 'Target_audience':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'target_audience'))]\n",
    "            relationship = 'Has_target_audience'\n",
    "\n",
    "        if relationship == 'Occupation_or_industry' or relationship == 'Username' or relationship == 'Self_description' or relationship == 'Location':\n",
    "            continue\n",
    "\n",
    "        if relationship == 'Product_category':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'product_name') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "            relationship = 'Has_product_category'\n",
    "\n",
    "        if relationship == 'Its_brand':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'product_name') & (relationship_df['target_attribute'] == 'brand'))]\n",
    "            # Has_brand\n",
    "            relationship_has_brand_df = relationship_df[relationship_df['source_attribute'] == 'product_name']\n",
    "            relationship = 'Has_brand'\n",
    "\n",
    "        if relationship == 'Interests':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "            relationship = 'Has_interest'\n",
    "\n",
    "        if relationship == 'Partner':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'brand')) |\n",
    "                                              ((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'partner')) |\n",
    "                                              ((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category')) |\n",
    "                                              ((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'influencer'))]\n",
    "            # Partner_brand\n",
    "            relationship_partner_brand_df = relationship_df[relationship_df['target_attribute'] == 'brand']\n",
    "            relationship = 'Partner_brand'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_brand_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_brand_df['source_attribute'].unique(), relationship_partner_brand_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_brand_df\n",
    "            # Partner_partner\n",
    "            relationship_partner_partner_df = relationship_df[relationship_df['target_attribute'] == 'partner']\n",
    "            relationship = 'Partner_partner'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_partner_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_partner_df['source_attribute'].unique(), relationship_partner_partner_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_partner_df\n",
    "            # Partner_product_category\n",
    "            relationship_partner_product_category_df = relationship_df[relationship_df['target_attribute'] == 'product_category']\n",
    "            relationship = 'Partner_product_category'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_product_category_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_product_category_df['source_attribute'].unique(), relationship_partner_product_category_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_product_category_df\n",
    "            # Partner_influencer\n",
    "            relationship_partner_influencer_df = relationship_df[relationship_df['target_attribute'] == 'influencer']\n",
    "            relationship = 'Partner_influencer'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_influencer_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_influencer_df['source_attribute'].unique(), relationship_partner_influencer_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_influencer_df\n",
    "            continue\n",
    "\n",
    "        if relationship == 'Brand_collaboration':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'brand'))]\n",
    "        \n",
    "        if relationship == 'Has_interest':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "        \n",
    "        print('The shape of the', relationship, 'dataframe is:', relationship_df.shape)\n",
    "        print('Attributes of the source and target:', relationship_df['source_attribute'].unique(), relationship_df['target_attribute'].unique())\n",
    "        edge_df_dict[relationship] = relationship_df\n",
    "\n",
    "    for relationship, df in edge_df_dict.items():\n",
    "        source_attribute = df['source_attribute'].iloc[0].capitalize()\n",
    "        target_attribute = df['target_attribute'].iloc[0].capitalize()\n",
    "        df = df[df['source'].isin(node_df_dict[source_attribute]['name']) & df['target'].isin(node_df_dict[target_attribute]['name'])]\n",
    "        print('The shape of the', relationship, 'dataframe is:', df.shape)\n",
    "        edge_df_dict[relationship] = df\n",
    "    \n",
    "    return edge_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df, nodes_df, label_df = load_data(use_multimodal=True)\n",
    "print()\n",
    "explore_edge_table(kg_df, nodes_df)\n",
    "multimodal_node_df_dict = create_node_table(nodes_df)\n",
    "multimodal_edge_df_dict = create_edge_table(kg_df, nodes_df, multimodal_node_df_dict)\n",
    "multimodal_label_df = label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df, nodes_df, label_df = load_data(use_multimodal=False)\n",
    "print()\n",
    "explore_edge_table(kg_df, nodes_df)\n",
    "nomultimodal_node_df_dict = create_node_table(nodes_df)\n",
    "nomultimodal_edge_df_dict = create_edge_table(kg_df, nodes_df, nomultimodal_node_df_dict)\n",
    "nomultimodal_label_df = label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kuzu\n",
    "from langchain.chains import KuzuQAChain\n",
    "from langchain_community.graphs import KuzuGraph\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kuzu_graph(node_df_dict, edge_df_dict):\n",
    "    db_name = \"influencer_kg.db\"\n",
    "    \n",
    "    # Clear previous database if it exists\n",
    "    if os.path.exists(db_name):\n",
    "        print(f\"Removing existing database: {db_name}\")\n",
    "        shutil.rmtree(db_name)\n",
    "    \n",
    "    # Create a new Kuzu database\n",
    "    db = kuzu.Database(db_name)\n",
    "    conn = kuzu.Connection(db)\n",
    "\n",
    "    print('----------Creating node tables----------')\n",
    "    nodename2node_dict = dict()\n",
    "    # Create node tables\n",
    "    for node_type, df in node_df_dict.items():\n",
    "        columns = df.columns.tolist()\n",
    "        create_query = f\"CREATE NODE TABLE {node_type} (\"\n",
    "        column_defs = []\n",
    "        for col in columns:\n",
    "            if node_type == 'Influencer' and col == 'follower_count':\n",
    "                column_defs.append(f\"{col} INT64\")\n",
    "            else:\n",
    "                column_defs.append(f\"{col} STRING\")\n",
    "        create_query += \", \".join(column_defs)\n",
    "        create_query += \", PRIMARY KEY (name))\"\n",
    "        print(f\"Executing query: {create_query}\")  # Debug print\n",
    "        conn.execute(create_query)\n",
    "        \n",
    "        # Import nodes directly from dataframe\n",
    "        print(f\"Importing nodes for {node_type}\")\n",
    "        conn.execute(f\"COPY {node_type} FROM df\")\n",
    "\n",
    "        nodename2node_dict[node_type] = df['name'].tolist()\n",
    "    print('\\n')\n",
    "\n",
    "    print('----------Creating edge tables----------')\n",
    "    # Create edge tables\n",
    "    for edge_type, df in edge_df_dict.items():\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        source_type = df['source_attribute'].iloc[0].capitalize()\n",
    "        target_type = df['target_attribute'].iloc[0].capitalize()\n",
    "\n",
    "        create_query = f\"CREATE REL TABLE {edge_type} (FROM {source_type} TO {target_type})\"\n",
    "        print(f\"Executing query: {create_query}\")  # Debug print\n",
    "        conn.execute(create_query)\n",
    "        \n",
    "        # Import relationships directly from dataframe\n",
    "        print(f\"Importing relationships for {edge_type}\")\n",
    "        df = df[['source', 'target']]\n",
    "        df = df[df['source'].isin(nodename2node_dict[source_type]) & df['target'].isin(nodename2node_dict[target_type])]\n",
    "        conn.execute(f\"COPY {edge_type} FROM df\")\n",
    "\n",
    "    return db, conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_db, multimodal_conn = create_kuzu_graph(multimodal_node_df_dict, multimodal_edge_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_graph = KuzuGraph(multimodal_db)\n",
    "\n",
    "multimodal_chain = KuzuQAChain.from_llm(\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    graph=multimodal_graph,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(multimodal_graph.get_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert in influencer marketing. You have been asked to analyze influencers and product categories.\n",
    "You have been given a Knowledge Graph (KG) that contains information about influencers, product categories, and their relationships.\n",
    "You need to answer the following question based on the KG provided:\n",
    "For the influencer '{influencer}', will this influencer be suitable for the product category '{product_category}'? \n",
    "You can only answer with 'Yes' or 'No'. Please show your reasoning step by step.\n",
    "Please use JSON format as output and only for output. The output contains two keys: prediction and reason.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_dict = {'user': [], 'target_entity': [], 'true_label': [], 'GPT-4o_output': []}\n",
    "for i, row in tqdm(multimodal_label_df.iterrows(), total=len(multimodal_label_df)):\n",
    "    influencer = row['user']\n",
    "    product_category = row['target_entity']\n",
    "    true_label = row['label']\n",
    "    prompt = prompt_template.format(influencer=influencer, product_category=product_category)\n",
    "    try:\n",
    "        result = multimodal_chain.invoke(prompt)\n",
    "    except:\n",
    "        result = 'Error'\n",
    "    result_df_dict['user'].append(influencer)\n",
    "    result_df_dict['target_entity'].append(product_category)\n",
    "    result_df_dict['true_label'].append(true_label)\n",
    "    result_df_dict['GPT-4o_output'].append(result)\n",
    "\n",
    "    result_df = pd.DataFrame(result_df_dict)\n",
    "    result_df.to_csv(save_dir.joinpath('GPT-4o_multimodal_output.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NoMultimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomultimodal_db, nomultimodal_conn = create_kuzu_graph(nomultimodal_node_df_dict, nomultimodal_edge_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomultimodal_graph = KuzuGraph(nomultimodal_db)\n",
    "\n",
    "nomultimodal_chain = KuzuQAChain.from_llm(\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    graph=nomultimodal_graph,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(nomultimodal_graph.get_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert in influencer marketing. You have been asked to analyze influencers and product categories.\n",
    "You have been given a Knowledge Graph (KG) that contains information about influencers, product categories, and their relationships.\n",
    "You need to answer the following question based on the KG provided:\n",
    "For the influencer '{influencer}', will this influencer be suitable for the product category '{product_category}'? \n",
    "You can only answer with 'Yes' or 'No'. Please show your reasoning step by step.\n",
    "Please use JSON format as output and only for output. The output contains two keys: prediction and reason.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_dict = {'user': [], 'target_entity': [], 'true_label': [], 'GPT-4o_output': []}\n",
    "for i, row in tqdm(nomultimodal_label_df.iterrows(), total=len(nomultimodal_label_df)):\n",
    "    influencer = row['user']\n",
    "    product_category = row['target_entity']\n",
    "    true_label = row['label']\n",
    "    prompt = prompt_template.format(influencer=influencer, product_category=product_category)\n",
    "    try:\n",
    "        result = nomultimodal_chain.invoke(prompt)\n",
    "    except:\n",
    "        result = 'Error'\n",
    "    result_df_dict['user'].append(influencer)\n",
    "    result_df_dict['target_entity'].append(product_category)\n",
    "    result_df_dict['true_label'].append(true_label)\n",
    "    result_df_dict['GPT-4o_output'].append(result)\n",
    "\n",
    "    result_df = pd.DataFrame(result_df_dict)\n",
    "    result_df.to_csv(save_dir.joinpath('GPT-4o_nomultimodal_output.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data/kg_dr/coldstart_processed')\n",
    "save_dir = Path('saved/kuzu_rag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kg_graph(label_df, userid2entityid, userid2relationship, \n",
    "                    target_entityid2entityid, target_entityid2relationship, \n",
    "                    id2node_dict, id2relationship_dict):\n",
    "    userid2user = dict(zip(label_df['user_id'], label_df['user']))\n",
    "    targetid2target = dict(zip(label_df['target_entity_id'], label_df['target_entity']))\n",
    "    id2node_dict.update(userid2user)\n",
    "    id2node_dict.update(targetid2target)\n",
    "    label_df = label_df[label_df['label'] == 1]\n",
    "    label_df = label_df[['user', 'target_entity']]\n",
    "    label_df = label_df.rename(columns={'user': 'source', 'target_entity': 'target'})\n",
    "    label_df['relationship'] = 'suitable_category'\n",
    "\n",
    "    kg_df_dict = {'source': [], 'target': [], 'relationship': []}\n",
    "    for userid, entityid_list in userid2entityid.items():\n",
    "        kg_df_dict['source'] += [id2node_dict[userid]] * len(entityid_list)\n",
    "        kg_df_dict['target'] += [id2node_dict[entityid] for entityid in entityid_list]\n",
    "        relationship_list = userid2relationship[userid]\n",
    "        kg_df_dict['relationship'] += [id2relationship_dict[relationship] for relationship in relationship_list]\n",
    "    for target_entityid, entityid_list in target_entityid2entityid.items():\n",
    "        kg_df_dict['source'] += [id2node_dict[target_entityid]] * len(entityid_list)\n",
    "        kg_df_dict['target'] += [id2node_dict[entityid] for entityid in entityid_list]\n",
    "        relationship_list = target_entityid2relationship[target_entityid]\n",
    "        kg_df_dict['relationship'] += [id2relationship_dict[relationship] for relationship in relationship_list]\n",
    "\n",
    "    kg_df = pd.DataFrame(kg_df_dict)\n",
    "    kg_df = pd.concat([kg_df, label_df])\n",
    "    kg_df = kg_df.drop_duplicates()\n",
    "    return kg_df\n",
    "\n",
    "def load_data(use_multimodal=False):\n",
    "    data_dir = Path('data/kg_dr/coldstart_processed')\n",
    "    if use_multimodal:\n",
    "        with open(data_dir.joinpath('multimodal-Seed0-suitable_category-data_train_dict-kfold0.pkl'), 'rb') as f:\n",
    "            train_dict = pickle.load(f)\n",
    "        with open(data_dir.joinpath('multimodal-Seed0-suitable_category-data_valid_dict-kfold0.pkl'), 'rb') as f:\n",
    "            valid_dict = pickle.load(f)\n",
    "        with open(data_dir.joinpath('multimodal-Seed0-suitable_category-data_test_dict-kfold0.pkl'), 'rb') as f:\n",
    "            test_dict = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_dir.joinpath('no_multimodal-Seed0-suitable_category-data_train_dict-kfold0.pkl'), 'rb') as f:\n",
    "            train_dict = pickle.load(f)\n",
    "        with open(data_dir.joinpath('no_multimodal-Seed0-suitable_category-data_valid_dict-kfold0.pkl'), 'rb') as f:\n",
    "            valid_dict = pickle.load(f)\n",
    "        with open(data_dir.joinpath('no_multimodal-Seed0-suitable_category-data_test_dict-kfold0.pkl'), 'rb') as f:\n",
    "            test_dict = pickle.load(f)\n",
    "\n",
    "    id2node_dict = train_dict['id2node']\n",
    "    id2relationship_dict = {v: k for k, v in train_dict['relationship2id'].items()}\n",
    "    \n",
    "    print('Get the KG dataframe from the train dictionary')\n",
    "    train_edge_df = train_dict['edges'][['source', 'target', 'relationship']]\n",
    "    train_label_df = train_dict['label'][['user', 'target_entity', 'label']]\n",
    "    train_label_df = train_label_df[train_label_df['label'] == 1]\n",
    "    train_label_df = train_label_df.rename(columns={'user': 'source', 'target_entity': 'target'})\n",
    "    train_label_df['relationship'] = 'suitable_category'\n",
    "    train_label_df = train_label_df[['source', 'target', 'relationship']]\n",
    "    train_kg_df = pd.concat([train_edge_df, train_label_df])\n",
    "\n",
    "    print('Get the KG dataframe from the valid dictionary')\n",
    "    valid_kg_df = create_kg_graph(valid_dict['label'], valid_dict['userid2entityid'], valid_dict['userid2relationship'], \n",
    "                                  valid_dict['target_entityid2entityid'], valid_dict['target_entityid2relationship'], \n",
    "                                  id2node_dict, id2relationship_dict)\n",
    "    \n",
    "    print('Get the KG dataframe from the test dictionary')\n",
    "    test_kg_df = create_kg_graph(test_dict['label'], test_dict['userid2entityid'], test_dict['userid2relationship'], \n",
    "                                 test_dict['target_entityid2entityid'], test_dict['target_entityid2relationship'], \n",
    "                                 id2node_dict, id2relationship_dict)\n",
    "    test_label_df = test_kg_df[test_kg_df['relationship'] == 'suitable_category']\n",
    "    test_kg_df = test_kg_df[test_kg_df['relationship'] != 'suitable_category']\n",
    "\n",
    "    print('Get the node dataframe')\n",
    "    all_node_list = list(set(train_kg_df['source']) | set(train_kg_df['target']) | \n",
    "                         set(valid_kg_df['source']) | set(valid_kg_df['target']) | \n",
    "                         set(test_kg_df['source']) | set(test_kg_df['target']) |\n",
    "                         set(test_label_df['source']) | set(test_label_df['target']))\n",
    "    nodes_df = pd.read_csv(data_dir.parent.joinpath('processed/nodes.csv'))\n",
    "    nodes_df = nodes_df[nodes_df['name'].isin(all_node_list)]\n",
    "    print('The shape of the node dataframe after filtering', nodes_df.shape)\n",
    "    # for nodes whose attribute is username, change the attribute to influencer\n",
    "    nodes_df.loc[nodes_df['attribute'] == 'username', 'attribute'] = 'influencer'\n",
    "    \n",
    "    return train_kg_df, valid_kg_df, test_kg_df, test_label_df, nodes_df\n",
    "\n",
    "def create_node_table(nodes_df):\n",
    "    node_df_dict = {}\n",
    "    attribute_list = list(set(nodes_df['attribute'].unique()))\n",
    "    for attribute in attribute_list:\n",
    "        attribute_df = nodes_df[nodes_df['attribute'] == attribute]\n",
    "        attribute_df = attribute_df[['name', 'attribute']]\n",
    "        attribute_df = attribute_df.drop_duplicates(subset=['name'])\n",
    "        attribute_df = attribute_df.dropna(subset=['name'])\n",
    "        # first letter uppercase\n",
    "        attribute = attribute.capitalize()\n",
    "        print('The shape of the', attribute, 'dataframe is:', attribute_df.shape)\n",
    "        node_df_dict[attribute] = attribute_df\n",
    "    return node_df_dict\n",
    "\n",
    "def explore_edge_table(edges_df, nodes_df):\n",
    "    nodes_filder_df = nodes_df.dropna(subset=['name'])\n",
    "    edges_df = edges_df[(edges_df['source'].isin(nodes_filder_df['name'])) & (edges_df['target'].isin(nodes_filder_df['name']))]\n",
    "    node2attribute_dict = dict(zip(nodes_filder_df['name'], nodes_filder_df['attribute']))\n",
    "\n",
    "    relationship_list = list(set(edges_df['relationship'].unique()))\n",
    "    for relationship in relationship_list:\n",
    "        relationship_df = edges_df[edges_df['relationship'] == relationship]\n",
    "        relationship_df = relationship_df[['source', 'target', 'relationship']]\n",
    "        relationship_df = relationship_df.drop_duplicates()\n",
    "        relationship_df = relationship_df.dropna(subset=['source', 'target', 'relationship'])\n",
    "        relationship_df['source_attribute'] = relationship_df['source'].map(node2attribute_dict)\n",
    "        relationship_df['target_attribute'] = relationship_df['target'].map(node2attribute_dict)\n",
    "        print('The shape of the', relationship, 'dataframe is:', relationship_df.shape)\n",
    "        print('The combination of source attribute and target attribute:')\n",
    "        print(relationship_df[['source_attribute', 'target_attribute']].value_counts())\n",
    "        print('\\n')\n",
    "\n",
    "def create_edge_table(edges_df, nodes_df, node_df_dict):\n",
    "    node_list = []\n",
    "    for df in node_df_dict.values():\n",
    "        node_list.extend(df['name'].tolist())\n",
    "    node_list = list(set(node_list))\n",
    "    edges_df = edges_df[(edges_df['source'].isin(node_list)) & (edges_df['target'].isin(node_list))]\n",
    "    \n",
    "    nodes_filder_df = nodes_df.dropna(subset=['name'])\n",
    "    node2attribute_dict = dict(zip(nodes_filder_df['name'], nodes_filder_df['attribute']))\n",
    "    \n",
    "    edge_df_dict = {}\n",
    "    relationship_list = list(set(edges_df['relationship'].unique()))\n",
    "    for relationship in relationship_list:\n",
    "        relationship_df = edges_df[edges_df['relationship'] == relationship]\n",
    "        relationship_df = relationship_df[['source', 'target', 'relationship']]\n",
    "        relationship_df = relationship_df.drop_duplicates()\n",
    "        relationship_df = relationship_df.dropna(subset=['source', 'target', 'relationship'])\n",
    "        relationship_df['source_attribute'] = relationship_df['source'].map(node2attribute_dict)\n",
    "        relationship_df['target_attribute'] = relationship_df['target'].map(node2attribute_dict)\n",
    "        relationship = relationship.capitalize()\n",
    "\n",
    "        if relationship == 'Recommend_product':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "            relationship = 'Recommend'\n",
    "        \n",
    "        if relationship == 'Target_audience':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'target_audience'))]\n",
    "            relationship = 'Has_target_audience'\n",
    "\n",
    "        if relationship == 'Occupation_or_industry' or relationship == 'Username' or relationship == 'Self_description' or relationship == 'Location':\n",
    "            continue\n",
    "\n",
    "        if relationship == 'Product_category':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'product_name') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "            relationship = 'Has_product_category'\n",
    "\n",
    "        if relationship == 'Its_brand':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'product_name') & (relationship_df['target_attribute'] == 'brand'))]\n",
    "            # Has_brand\n",
    "            relationship_has_brand_df = relationship_df[relationship_df['source_attribute'] == 'product_name']\n",
    "            relationship = 'Has_brand'\n",
    "\n",
    "        if relationship == 'Interests':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "            relationship = 'Has_interest'\n",
    "\n",
    "        if relationship == 'Partner':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'brand')) |\n",
    "                                              ((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'partner')) |\n",
    "                                              ((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category')) |\n",
    "                                              ((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'influencer'))]\n",
    "            # Partner_brand\n",
    "            relationship_partner_brand_df = relationship_df[relationship_df['target_attribute'] == 'brand']\n",
    "            relationship = 'Partner_brand'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_brand_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_brand_df['source_attribute'].unique(), relationship_partner_brand_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_brand_df\n",
    "            # Partner_partner\n",
    "            relationship_partner_partner_df = relationship_df[relationship_df['target_attribute'] == 'partner']\n",
    "            relationship = 'Partner_partner'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_partner_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_partner_df['source_attribute'].unique(), relationship_partner_partner_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_partner_df\n",
    "            # Partner_product_category\n",
    "            relationship_partner_product_category_df = relationship_df[relationship_df['target_attribute'] == 'product_category']\n",
    "            relationship = 'Partner_product_category'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_product_category_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_product_category_df['source_attribute'].unique(), relationship_partner_product_category_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_product_category_df\n",
    "            # Partner_influencer\n",
    "            relationship_partner_influencer_df = relationship_df[relationship_df['target_attribute'] == 'influencer']\n",
    "            relationship = 'Partner_influencer'\n",
    "            print('The shape of the', relationship, 'dataframe is:', relationship_partner_influencer_df.shape)\n",
    "            print('Attributes of the source and target:', relationship_partner_influencer_df['source_attribute'].unique(), relationship_partner_influencer_df['target_attribute'].unique())\n",
    "            edge_df_dict[relationship] = relationship_partner_influencer_df\n",
    "            continue\n",
    "\n",
    "        if relationship == 'Brand_collaboration':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'brand'))]\n",
    "        \n",
    "        if relationship == 'Has_interest':\n",
    "            relationship_df = relationship_df[((relationship_df['source_attribute'] == 'influencer') & (relationship_df['target_attribute'] == 'product_category'))]\n",
    "        \n",
    "        print('The shape of the', relationship, 'dataframe is:', relationship_df.shape)\n",
    "        print('Attributes of the source and target:', relationship_df['source_attribute'].unique(), relationship_df['target_attribute'].unique())\n",
    "        edge_df_dict[relationship] = relationship_df\n",
    "\n",
    "    for relationship, df in edge_df_dict.items():\n",
    "        source_attribute = df['source_attribute'].iloc[0].capitalize()\n",
    "        target_attribute = df['target_attribute'].iloc[0].capitalize()\n",
    "        df = df[df['source'].isin(node_df_dict[source_attribute]['name']) & df['target'].isin(node_df_dict[target_attribute]['name'])]\n",
    "        print('The shape of the', relationship, 'dataframe is:', df.shape)\n",
    "        edge_df_dict[relationship] = df\n",
    "    \n",
    "    return edge_df_dict\n",
    "\n",
    "def zero_shot_process(use_multimodal=False):\n",
    "    train_kg_df, valid_kg_df, test_kg_df, test_label_df, nodes_df = load_data(use_multimodal=use_multimodal)\n",
    "    kg_df = pd.concat([train_kg_df, valid_kg_df])\n",
    "    print('The shape of the KG dataframe:', kg_df.shape)\n",
    "    explore_edge_table(kg_df, nodes_df)\n",
    "    node_df_dict = create_node_table(nodes_df)\n",
    "    edge_df_dict = create_edge_table(kg_df, nodes_df, node_df_dict)\n",
    "    label_df = test_label_df\n",
    "    return node_df_dict, edge_df_dict, label_df, test_kg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_node_df_dict, multimodal_edge_df_dict, multimodal_label_df, multimodal_test_kg_df = zero_shot_process(use_multimodal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomultimodal_node_df_dict, nomultimodal_edge_df_dict, nomultimodal_label_df, nomultimodal_test_kg_df = zero_shot_process(use_multimodal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kuzu\n",
    "from langchain.chains import KuzuQAChain\n",
    "from langchain_community.graphs import KuzuGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def create_kuzu_graph(node_df_dict, edge_df_dict):\n",
    "    db_name = \"influencer_kg.db\"\n",
    "    \n",
    "    # Clear previous database if it exists\n",
    "    if os.path.exists(db_name):\n",
    "        print(f\"Removing existing database: {db_name}\")\n",
    "        shutil.rmtree(db_name)\n",
    "    \n",
    "    # Create a new Kuzu database\n",
    "    db = kuzu.Database(db_name)\n",
    "    conn = kuzu.Connection(db)\n",
    "\n",
    "    print('----------Creating node tables----------')\n",
    "    nodename2node_dict = dict()\n",
    "    # Create node tables\n",
    "    for node_type, df in node_df_dict.items():\n",
    "        columns = df.columns.tolist()\n",
    "        create_query = f\"CREATE NODE TABLE {node_type} (\"\n",
    "        column_defs = []\n",
    "        for col in columns:\n",
    "            if node_type == 'Influencer' and col == 'follower_count':\n",
    "                column_defs.append(f\"{col} INT64\")\n",
    "            else:\n",
    "                column_defs.append(f\"{col} STRING\")\n",
    "        create_query += \", \".join(column_defs)\n",
    "        create_query += \", PRIMARY KEY (name))\"\n",
    "        print(f\"Executing query: {create_query}\")  # Debug print\n",
    "        conn.execute(create_query)\n",
    "        \n",
    "        # Import nodes directly from dataframe\n",
    "        print(f\"Importing nodes for {node_type}\")\n",
    "        conn.execute(f\"COPY {node_type} FROM df\")\n",
    "\n",
    "        nodename2node_dict[node_type] = df['name'].tolist()\n",
    "    print('\\n')\n",
    "\n",
    "    print('----------Creating edge tables----------')\n",
    "    # Create edge tables\n",
    "    for edge_type, df in edge_df_dict.items():\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        source_type = df['source_attribute'].iloc[0].capitalize()\n",
    "        target_type = df['target_attribute'].iloc[0].capitalize()\n",
    "\n",
    "        create_query = f\"CREATE REL TABLE {edge_type} (FROM {source_type} TO {target_type})\"\n",
    "        print(f\"Executing query: {create_query}\")  # Debug print\n",
    "        conn.execute(create_query)\n",
    "        \n",
    "        # Import relationships directly from dataframe\n",
    "        print(f\"Importing relationships for {edge_type}\")\n",
    "        df = df[['source', 'target']]\n",
    "        df = df[df['source'].isin(nodename2node_dict[source_type]) & df['target'].isin(nodename2node_dict[target_type])]\n",
    "        conn.execute(f\"COPY {edge_type} FROM df\")\n",
    "\n",
    "    return db, conn\n",
    "\n",
    "def create_triplet(source, kg_df):\n",
    "    triplet_df = kg_df[kg_df['source'] == source]\n",
    "    triplet_df = triplet_df[['source', 'target', 'relationship']]\n",
    "    triplet_df = triplet_df.drop_duplicates()\n",
    "    triplet_str = ''\n",
    "    for i, row in triplet_df.iterrows():\n",
    "        triplet_str += f\"{row['source']}, {row['relationship']}, {row['target']}.\\n\"\n",
    "    return triplet_str\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are an expert in influencer marketing. You have been asked to analyze influencers and product categories.\n",
    "You have been given a Knowledge Graph (KG) that contains information about influencers, product categories, and their relationships.\n",
    "You need to answer the following question based on the given KG and external information of an influencer and a product category provided.\n",
    "The external information is in triplet format: (head, relation, tail).\n",
    "For the influencer '{influencer}', we have the following information: {influencer_info}.\n",
    "For the product category '{product_category}', we have the following information: {product_category_info}.\n",
    "Now, based on the KG and the external information, will this influencer be suitable for the product category '{product_category}'?\n",
    "You can only answer with 'Yes' or 'No'. Please show your reasoning step by step.\n",
    "Please use JSON format as output and only for output. The output contains two keys: prediction and reason.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_db, multimodal_conn = create_kuzu_graph(multimodal_node_df_dict, multimodal_edge_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_graph = KuzuGraph(multimodal_db)\n",
    "\n",
    "multimodal_chain = KuzuQAChain.from_llm(\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    graph=multimodal_graph,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(multimodal_graph.get_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer = 'in2itcosmetics.my'\n",
    "product_category = 'Beauty & Personal Care'\n",
    "influencer_info = create_triplet(influencer, multimodal_test_kg_df)\n",
    "product_category_info = create_triplet(product_category, multimodal_test_kg_df)\n",
    "prompt = prompt_template.format(influencer=influencer, product_category=product_category, \n",
    "                                influencer_info=influencer_info, product_category_info=product_category_info)\n",
    "multimodal_chain.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_dict = {'user': [], 'target_entity': [], 'true_label': [], 'GPT-4o_output': []}\n",
    "for i, row in tqdm(multimodal_label_df.iterrows(), total=len(multimodal_label_df)):\n",
    "    influencer = row['source']\n",
    "    product_category = row['target']\n",
    "    true_label = 1\n",
    "    influencer_info = create_triplet(influencer, multimodal_test_kg_df)\n",
    "    product_category_info = create_triplet(product_category, multimodal_test_kg_df)\n",
    "    prompt = prompt_template.format(influencer=influencer, product_category=product_category,\n",
    "                                    influencer_info=influencer_info, product_category_info=product_category_info)\n",
    "    try:\n",
    "        result = multimodal_chain.invoke(prompt)\n",
    "    except:\n",
    "        result = 'Error'\n",
    "    result_df_dict['user'].append(influencer)\n",
    "    result_df_dict['target_entity'].append(product_category)\n",
    "    result_df_dict['true_label'].append(true_label)\n",
    "    result_df_dict['GPT-4o_output'].append(result)\n",
    "\n",
    "    result_df = pd.DataFrame(result_df_dict)\n",
    "    result_df.to_csv(save_dir.joinpath('zero-shot_GPT-4o_multimodal_output.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NoMultimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomultimodal_db, nomultimodal_conn = create_kuzu_graph(nomultimodal_node_df_dict, nomultimodal_edge_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomultimodal_graph = KuzuGraph(nomultimodal_db)\n",
    "\n",
    "nomultimodal_chain = KuzuQAChain.from_llm(\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "    graph=nomultimodal_graph,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(nomultimodal_graph.get_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomultimodal_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_dict = {'user': [], 'target_entity': [], 'true_label': [], 'GPT-4o_output': []}\n",
    "for i, row in tqdm(nomultimodal_label_df.iterrows(), total=len(nomultimodal_label_df)):\n",
    "    influencer = row['source']\n",
    "    product_category = row['target']\n",
    "    true_label = 1\n",
    "    influencer_info = create_triplet(influencer, nomultimodal_test_kg_df)\n",
    "    product_category_info = create_triplet(product_category, nomultimodal_test_kg_df)\n",
    "    prompt = prompt_template.format(influencer=influencer, product_category=product_category,\n",
    "                                    influencer_info=influencer_info, product_category_info=product_category_info)\n",
    "    try:\n",
    "        result = nomultimodal_chain.invoke(prompt)\n",
    "    except:\n",
    "        result = 'Error'\n",
    "    result_df_dict['user'].append(influencer)\n",
    "    result_df_dict['target_entity'].append(product_category)\n",
    "    result_df_dict['true_label'].append(true_label)\n",
    "    result_df_dict['GPT-4o_output'].append(result)\n",
    "\n",
    "    result_df = pd.DataFrame(result_df_dict)\n",
    "    result_df.to_csv(save_dir.joinpath('zero-shot_GPT-4o_nomultimodal_output.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
